---
title: "Advanced Biosurveillance"
author: "Jarad Niemi"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
  pdf_document:
    toc: true
vignette: >
  %\VignetteIndexEntry{Advanced Biosurveillance}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r}
library(ggplot2)
library(plyr)
library(reshape2)
library(RColorBrewer) 
library(ISDSWorkshop)
workshop(launch_index=FALSE)
```

```{r}
# Read csv files
GI     = read.csv("GI.csv")
icd9df = read.csv("icd9.csv")
```

```{r}
# Mutate data.frame
GI = mutate(GI,
            date      = as.Date(date),
            weekC     = cut(date, breaks="weeks"),
            week      = as.numeric(weekC),
            weekD     = as.Date(weekC),
            facility  = as.factor(facility),
            icd9class = factor(cut(icd9, 
                            breaks = icd9df$code_cutpoint, 
                            labels = icd9df$classification[-nrow(icd9df)], 
                            right  = TRUE)),
            ageC      = cut(age, 
                            breaks = c(-Inf, 5, 18, 45 ,60, Inf)),
            zip3      = trunc(zipcode/100))
```


# <a name="exporting_tables"></a> Exporting tables

There are many ways to exporting tables. Here I will cover two basic approachess that are simple and work well. 

- cut-and-paste
- create HTML table and cut-and-paste to Word

There are more sophisticated approaches that I will not cover:

- [using the rtf package](http://thomasleeper.com/Rcourse/Tutorials/wordoutput.html)
- [writing a whole doc fie in R](http://www.r-statistics.com/2013/03/write-ms-word-document-using-r-with-as-little-overhead-as-possible/)

## Cut-and-paste 

You can cut-and-paste directly from R. 

```{r}
ga_l = ddply(GI, .(gender, ageC), summarize, count = length(id))
ga_w = dcast(ga_l, gender~ageC) # Long to wide
print(ga_w, row.names=FALSE)
```

Cut-and-pasting this table is done in ASCII format. This looks good in a **plain text** document, e.g. Notepad, TextEdit, and some email, but will not look good in other formats, e.g. docx.


## Create HTML table

```{r}
library(xtable)
tab = xtable(ga_w,
             caption = "Total GI cases by Sex and Age Category",
             label   = "myHTMLanchor",
             align   = "ll|rrrrr") # rownames gets a column
```

Save the table to a file

```{r}
print(tab, file="table.html", type="html", include.rownames=FALSE)
```


## Output for this HTML table

The HTML code looks like 

```{r}
print(tab, type="html", include.rownames=FALSE)
```

and the resulting table looks like 

```{r, results='asis'}
print(tab, type="html", include.rownames=FALSE)
```


## Copy-and-paste table to Word

Now you can 

1. Open the file (`table.html`)
1. Copy-and-paste this table to Word. 


## Activity - exporting tables

Create a Word table for the number of cases by facility and age category.

```{r, echo=FALSE}
# Summarize data by facility and age category

# Reshape data from long to wide format

# Create HTML table

# Save HTML to file

# Copy-and-paste table into Word
```

When you have completed the activity, compare your results to the [solutions](biosurveillance-solution.html#exporting_tables).


# <a name="maps"></a> Maps

The packages `ggplot2` and `maps` can be used together to make maps.

Map of the continental US
```{r}
library(maps)
states = map_data("state")
ggplot(states, aes(x=long, y=lat, group=group)) + geom_polygon()
```

Map of the counties in the continental US
```{r}
counties = map_data("county")
ggplot(counties, aes(x=long, y=lat, group=group)) + geom_polygon(color="white")
```

Map of the counties in Iowa
```{r}
ggplot(subset(counties, region=="iowa"), 
       aes(x=long, y=lat, group=group)) + geom_polygon(fill="red", color="black")
```

## Construct an appropriate data set

To make an informative map, we need to add data. 

```{r}
fluTrends = read.csv("fluTrends.csv", check.names=FALSE)
```

For simplicity, only keep the most recent 12 weeks on states. 

```{r}
nr = nrow(fluTrends)
flu_w = fluTrends[(nr-11):nr, c(1,3:53)]
dim(flu_w)
```

Reshape to long format

```{r}
flu_l = melt(flu_w, id.var='Date',
             variable.name='region', # to match map_data
             value.name='index')
```

## Merge fluTrends data with map_data

The region names in `map_data` are lower case, so use `tolower()` to convert all the region names in flu_l to lowercase. Then the `map_data` and fluTrends data are merged using `merge()`. 

```{r}
head(unique(states$region))
flu_l$region = tolower(flu_l$region)
states_merged = merge(states, flu_l, sort=FALSE, by='region')
```

## Make the plots

Most recent Google Flu Trend data.

```{r}
states_merged$Date = as.Date(states_merged$Date)
mx_date = max(states_merged$Date)
ggplot(subset(states_merged, Date == mx_date), 
       aes(x=long, y=lat, group=group, fill=index)) + 
  geom_polygon() + 
  labs(title=paste('Google Flu Trends on', mx_date), x='', y='') +
  theme_minimal() + 
  theme(legend.title = element_blank()) +
  coord_map("cylindrical") + 
  scale_fill_gradientn(colours=brewer.pal(9,"Reds")) # Thanks Annie Chen
```

Last 12 weeks.

```{r}
ggplot(states_merged, 
       aes(x=long, y=lat, group=group, fill=index)) + 
  geom_polygon() + 
  labs(title='Google Flu Trends', x='', y='') +
  theme_minimal() + 
  theme(legend.title = element_blank()) +
  facet_wrap(~Date) + 
  coord_map("cylindrical") + 
  scale_fill_gradientn(colours=brewer.pal(9,"Reds")) 
```


## Activity 

Modify the code to determine what elements of the map are affected.

Advanced: Download the data directly from <http://www.google.org/flutrends/us/data.txt> using `read.csv' and then construct a map of the most recent Google Flu Trends data. 

```{r, echo=FALSE}
# Construct Google Flu Trends map
```

When you have completed the activity, compare your results to the [solutions](biosurveillance-solution.html#maps).



# <a name="Packages"></a> Packages

A package provides additional functionality besides what base installation of R provides. You have already used a number of additional packages:

- ggplot2
- ISDSWorkshop
- maps
- plyr
- reshape2
- xtable

The Comprehensive R Archive Network (CRAN) has over 6,000 packages. These packages can be installed using the `install.packages()` function, e.g. 

```{r, eval=FALSE}
install.packages("ggplot2")
```

For many reasons, packages may not be on CRAN but may be available from other sources:

- [Github](http://github.com/)
- [Bioconductor](http://www.bioconductor.org/)
- Source file (tar.gz)


## Github

To install a package from github, you can use the `install_github()` function from the `devtools` package. For example,

```{r, eval=FALSE}
# install.packages("devtools")
library(devtools)
install_github('nandadorea/vetsyn')
```

This will not install any vignettes which is why I didn't use this method for this workshop.



## Bioconductor 

Bioconductor provides tools for high-throughput genomic data. There are over 900 packages available from bioconductor. To install bioconductor, use 

```{r, eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite()
```

Then to install a package from bioconductor use 

```{r, eval=FALSE}
biocLite("edgeR")
```

The bioconductor repository may be useful in the future for public health biosurveillance.


## Source

All packages can be installed from their source. If a package is not available in a repository, then this is the only way to install the package. To install from source download the source file (.tar.gz) and then use the `install.packages()` function with arguments `repos=NULl` and `type="source"`. For example, to install the ISDSWorkshop package you used 

```{r, eval=FALSE}
install.packages("ISDSWorkshop_0.1.tar.gz", 
                 repos = NULL, 
                 type  = "source")
```



## Packages for surveillance

Some [packages for performing surveillance](http://www.ij-healthgeographics.com/content/9/1/16) are 

- [accrued](http://cran.r-project.org/web/packages/accrued/index.html)
- [Epi](http://cran.r-project.org/web/packages/Epi/index.html)
- [SpatialEpi](http://cran.r-project.org/web/packages/SpatialEpi/index.html)
- [surveillance](http://cran.r-project.org/web/packages/surveillance/index.html)
- [vetsyn](https://github.com/nandadorea/vetsyn)


## SpatialEpi - Kulldorff example

The `SpatialEpi` package implements the Kulldorff cluster detection method in the `kulldorff()` function. 

Setting up the analysis (taken directly from the example)
```{r}
library(SpatialEpi)

## Load Pennsylvania Lung Cancer Data
data(pennLC)
data <- pennLC$data

## Process geographical information and convert to grid
geo <- pennLC$geo[,2:3]
geo <- latlong2grid(geo)

## Get aggregated counts of population and cases for each county
population <- tapply(data$population, data$county, sum)
cases      <- tapply(data$cases,      data$county, sum)

## Based on the 16 strata levels, compute expected numbers of disease
n.strata       <- 16
expected.cases <- expected(data$population, data$cases, n.strata)

## Set Parameters
pop.upper.bound <- 0.5
n.simulations   <- 999
alpha.level     <- 0.05
plot            <- TRUE
```

## SpatialEpi - Kulldorff example

Plot the data

```{r}
clr = cases/population
clr = 1-clr/max(clr) # make sure range is (0,1)
plot(pennLC$spatial.polygon, axes=TRUE, col=rgb(1, clr, clr))
```

## SpatialEpi - Kulldorff example

Run the analysis and plot the results (directly from the example)

```{r}
## Kulldorff using Binomial likelihoods
binomial <- kulldorff(geo, cases, population, NULL, pop.upper.bound, n.simulations, 
  alpha.level, plot)
cluster <- binomial$most.likely.cluster$location.IDs.included

## plot
plot(pennLC$spatial.polygon,axes=TRUE)
plot(pennLC$spatial.polygon[cluster],add=TRUE,col="red")
title("Most Likely Cluster")
```


## Activity - Install the `surveillance` package

If you are connected to the internet, try installing the `surveillance` package. 
If you are successful, look at its help file.

```{r, echo=FALSE}
# Install the surveillance package
```


When you have completed the activity, compare your results to the [solutions](biosurveillance-solution.html#packages).





# <a name="functions"></a> Functions

Packages are typically a collection of functions. But you can write your own. For example,

```{r}
add = function(a,b) {
  return(a+b)
}
add(1,2)
```

or 

```{r}
add_vector = function(v) {
  sum = 0
  for (i in 1:length(v)) sum = sum + v[i]
  return(sum)
}
```

## A simple outbreak detection function

Here is a simple outbreak detection function

```{r}
alert = function(y,threshold=100) {
  # y is the time series 
  # an alert is issue for any y above the threshold (default is 100)
  factor(ifelse(y>threshold, "Yes", "No"))
}
```

Run this on our weekly GI data.

```{r}
GI_w = ddply(GI, .(weekD), summarize, count = length(id))
GI_w$alert = alert(y = GI_w$count, threshold = 150)
ggplot(GI_w, aes(x=weekD, y=count, color=alert)) + 
  geom_point() + 
  scale_color_manual(values=c("black","red"))
```


# <a name="batch"></a> R in batch

For routine analysis, it can be helpful to run R in batch mode rather than interactively. To do this, create a script and save the script with a .R extension, e.g. `script.R`:

```{r, eval=FALSE}
# Read in the data perhaps as a csv file

# Create some table and save them to html files

# Create some figures and save them to jpegs

# Run some outbreak detection algorithms and produce figures
```

Now, from the command line run

    R CMD BATCH script.R
    
Now each week you can update the csv file and then just run the script which will create all new tables and figures. 


# <a name="shiny"></a> Shiny apps

R can be used to create HTML applications through the `shiny` package. The code is written entirely in R, although you can use cascading style sheets (CSS) if you want to update how it looks. [Here is an example](http://spark.rstudio.com/ejahanpour/SampleData/).

